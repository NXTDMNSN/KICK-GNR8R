{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "![KICKGNR8R BLACK MED.png](data:image/png;base64,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)"
      ],
      "metadata": {
        "id": "YW9OHqsToYKy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ☢  DIGITAL WARFARE - KICK-GNR8R  ☢\n"
      ],
      "metadata": {
        "id": "4bZV23WUnC3U"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HHcTRGvUmoME"
      },
      "source": [
        "**DIGITAL WARFARE** - ***DIGITALLY DISTORTED DATA DESIGNED TO DESTROY THE DANCE MUSIC INDUSTRY***\n",
        "\n",
        "---\n",
        "\n",
        "KICK-GNR8R_**GNR8** is a machine learning algorithm designed to generate Hardstyle Kicks from previously trained checkpoint files. The CKPT file provided was trained on over 1500 Hard Dance kicks from various genres spanning Rawstyle to Reverse bass.\n",
        "\n",
        "It is an extremely powerful tool for producers to generate absolutely unique professional sounding Kickdrums. The days of ripping kicks are over.\n",
        "This tool is not intended for replacing the traditional process of sound design and kick production, but rather as a companion to streamline the process by generating samples which can be refined layered, and elaborated as most kicks are done today. You can even train a CKPT with your own dataset!\n",
        "\n",
        "\n",
        "Input your CHECKPOINT file that you created in [KICK_GNR8R_**TRaiNR**](https://colab.research.google.com/drive/1FkGcp0_xDHbb6Xi9BAoEDqaqwtG5twMf?usp=sharing)\n",
        "\n",
        "---\n",
        "\n",
        "**Audio diffusion tools in this notebook**:\n",
        "\n",
        "- KICK GNR8R\n",
        ">  Unconditional (random) Kick sample Generator\n",
        "- R3GNR8R\n",
        "> Audio Sample Regenerator / Style Transfer using 2 input Samples\n",
        "- INTERPOL8R\n",
        "> Interpolation between 2 audio files to blend them in a specified number of steps\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1iZwJ9ong-pH"
      },
      "source": [
        "# **INSTRUCTIONS** 📖 ℹ\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-ITvsXU6hCAx"
      },
      "source": [
        "## PREREQUISITES\n",
        "- Sign up for free Gmail account and connect Google Drive\n",
        "- Purchase a Google Colab Subscription (100 kicks = ~$10) to access Nvidia A100 GPUs\n",
        "- Run 'Setup' Section to check GPU, prep drive, and install dependencies\n",
        "- Select the model CKPT you trained using [KICK_GNR8R_**TRaiNR**](https://colab.research.google.com/drive/1FkGcp0_xDHbb6Xi9BAoEDqaqwtG5twMf?usp=sharing)\n",
        "- Select Sampler type, and adjust settings.\n",
        "- Optionaly, check the `save_to_wandb` option [Weights & Biases](https://www.wandb.ai/site) to track performance, versions, and create data analysis on your runs.\n",
        "---\n",
        "## - KICK-GNR8R -\n",
        "---\n",
        "## GENERATE RANDOM KICKS\n",
        "- Select desired quantity of samples to generate\n",
        "- Select appropriate sampler steps for the generator\n",
        "- Run the [GNR8R Cell](https://colab.research.google.com/drive/1FKGY9U91q0njtIpOLIcoJ11dP8fbTOv3#scrollTo=_GQK9yZHTr_z&line=1&uniqifier=1) to generate samples\n",
        "\n",
        "---\n",
        "## - R3GENER8R -\n",
        "\n",
        "\n",
        "> ## LAYER & MIX\n",
        "- Record a file, enter the path to an audio file you want to regenerate, or upload a file when prompted\n",
        "\n",
        "\n",
        "> ## INTERPOL8R\n",
        "- Enter the paths to two audio files you want to interpolate between, or upload them when prompted\n",
        "- Make sure the \"skip_for_run_all\" checkbox is unchecked\n",
        "- Run the cell under the \"Interpolate between sounds\" header\n",
        "\n",
        "> ## STYLE TRANSFER\n",
        "- Enter a path to save your audio recordings\n",
        "- Enter the number of audio recordings you want to combine into one\n",
        "- Run the cell under the \"Regenerate your own sound from the recording\" header\n",
        "- Make sure the \"skip_for_run_all\" checkbox is unchecked"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pJkAc1j4pfAt"
      },
      "source": [
        "## **LICENSE AND TERMS**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u97w34BXmust"
      },
      "source": [
        "Licensed under the CC-1.0 LICENSE\n",
        "\n",
        "Copyright (c) 2023 Digital Warfare\n",
        "\n",
        "---\n",
        "\n",
        "This software and all data contained herewithin is property of \"Digital Warfare\", you may not copy, modify, merge, publish, distribute, sublicense, and/or sell any portion of this software unless with prior written permission from \"Digital Warfare\"\n",
        "\n",
        "Permission is hereby granted to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to operate the Software to generate novel audio files, including without limitation, the rights to use, copy, modify, publish, distribute, sublicense, and/or sell the data produced by this software herewithin in their own productions, and to permit persons to whom the data produced by the Software is furnished to do so, subject to the following conditions:\n",
        "\n",
        "---\n",
        "\n",
        "- Under no circumstance shall the user disclose the source of generated audio files whereof, or existence of (the \"Software\") in question.\n",
        "\n",
        "- By accessing the Software, the user agrees to participate in a private beta test of the Software and use the Software to train an AI using their own datasets. The user's uploaded data may be collected for research purposes in accordance with EU Regulation 6637/19 - 2016/0280(COD) and may be used to refine future versions of the Software. \n",
        "\n",
        "- (\"the Owner\") of the Software ('Digital Warfare\") shall not create datasets or products from the user's data for commercial purposes or public release without the explicit consent and a royalty contract with the user. The owner shall not publicly reveal any information about any beta tester or the sources of the data used in any dataset without the user's consent.\n",
        "\n",
        "- By using the Software, the user agrees that their data may be collected and used to refine future versions of the Software. Due to the nature of artificial intelligence, it is not possible to reverse engineer a checkpoint file to its source files, and thus the user's source code will remain safe. The Software requires high-quality data in order to produce the best results.\n",
        "\n",
        "- Users must use utmost discretion and secrecy if disclosing the nature of (the \"Software\") as it has the potential to disrupt the status quo of the industry to which the audio files pertain.\n",
        "\n",
        "- The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.\n",
        "\n",
        "---\n",
        "\n",
        "You have the right to use this software to generate novel audio files and use, copy, modify, merge, publish, distribute, sublicense, and sell the audio data produced by the software in your own productions. You can also give others permission to use the audio data prduced by the software. The software is provided \"as is\" and without warranty. The authors and copyright holders are not liable for any claims, damages, or other liability arising from the use of the software. The person or entity using the software has the right to assert ownership over the data generated by the software, including audio files, checkpoints, datasets, and other data. This data is considered the property of the person or entity using the software and can be used in any manner, including creating songs, publications, and performances, and asserting copyright. By using the software, you agree to the terms and conditions.\n",
        "\n",
        "---\n",
        "\n",
        "By using this Software, the user agrees to these terms\n",
        "\n",
        "Copyright (c) 2022 Digital Warfare\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lU97ZiP7nSKS"
      },
      "source": [
        "# **SETUP** 🚛\n",
        "RUN ALL IN THIS SECTION BEFORE GENERATING"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "cellView": "form",
        "id": "mxb-qgh0nUOf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "84973dea-bf0d-496d-a415-e0ec094ebd66"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU 0: A100-SXM4-40GB (UUID: GPU-7b4cc6a2-f4a9-ef87-c778-09aca9282c9e)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#@title CHECK GPU STATUS\n",
        "import subprocess\n",
        "simple_nvidia_smi_display = True#@param {type:\"boolean\"}\n",
        "if simple_nvidia_smi_display:\n",
        "    #!nvidia-smi\n",
        "    nvidiasmi_output = subprocess.run(['nvidia-smi', '-L'], stdout=subprocess.PIPE).stdout.decode('utf-8')\n",
        "    print(nvidiasmi_output)\n",
        "else:\n",
        "    #!nvidia-smi -i 0 -e 0\n",
        "    nvidiasmi_output = subprocess.run(['nvidia-smi'], stdout=subprocess.PIPE).stdout.decode('utf-8')\n",
        "    print(nvidiasmi_output)\n",
        "    nvidiasmi_ecc_note = subprocess.run(['nvidia-smi', '-i', '0', '-e', '0'], stdout=subprocess.PIPE).stdout.decode('utf-8')\n",
        "    print(nvidiasmi_ecc_note)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9ufsXWZk4Nkv"
      },
      "source": [
        "## INSTALL DEPENDENCIES AND RESTART RUNTIME\n",
        "\n",
        "**The session will crash to restart automatically, don't worry about the error. This is to ensure the proper dependencies are installed**\n",
        "\n",
        "**Once the notebook restarts, continue with the steps below**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "y9BS0ks1oEgP"
      },
      "outputs": [],
      "source": [
        "#@title INSTALL, RESTART, AND RUN AGAIN\n",
        "\n",
        "from IPython.display import clear_output  \n",
        "import os, signal\n",
        "\n",
        "\n",
        "\n",
        "#@markdown \n",
        "\n",
        "!git clone https://github.com/harmonai-org/sample-generator\n",
        "!git clone --recursive https://github.com/crowsonkb/v-diffusion-pytorch\n",
        "!pip install /content/sample-generator\n",
        "!pip install /content/v-diffusion-pytorch\n",
        "!pip install ipywidgets==7.7.1 gradio\n",
        "!pip install k-diffusion\n",
        "\n",
        "os.kill(os.getpid(), signal.SIGKILL)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## PREPARE FOLDERS\n"
      ],
      "metadata": {
        "id": "iJhSysRdwku9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "T_mFtzHvnlJL"
      },
      "outputs": [],
      "source": [
        "import subprocess, os, sys, ipykernel\n",
        "\n",
        "def gitclone(url, targetdir=None):\n",
        "    if targetdir:\n",
        "        res = subprocess.run(['git', 'clone', url, targetdir], stdout=subprocess.PIPE).stdout.decode('utf-8')\n",
        "    else:\n",
        "        res = subprocess.run(['git', 'clone', url], stdout=subprocess.PIPE).stdout.decode('utf-8')\n",
        "    print(res)\n",
        "\n",
        "def pipi(modulestr):\n",
        "    res = subprocess.run(['pip', 'install', modulestr], stdout=subprocess.PIPE).stdout.decode('utf-8')\n",
        "    print(res)\n",
        "\n",
        "def pipie(modulestr):\n",
        "    res = subprocess.run(['git', 'install', '-e', modulestr], stdout=subprocess.PIPE).stdout.decode('utf-8')\n",
        "    print(res)\n",
        "\n",
        "def wget(url, outputdir):\n",
        "    # Using the !wget command instead of the subprocess to get the loading bar\n",
        "    !wget $url -O $outputdir\n",
        "    # res = subprocess.run(['wget', url, '-P', f'{outputdir}'], stdout=subprocess.PIPE).stdout.decode('utf-8')\n",
        "    # print(res)\n",
        "\n",
        "try:\n",
        "    from google.colab import drive\n",
        "    print(\"Google Colab detected.\")\n",
        "    is_colab = True\n",
        "    #@markdown **CONNECT GOOGLE DRIVE**\n",
        "    google_drive = True #@param {type:\"boolean\"}\n",
        "    if google_drive:\n",
        "      print(\"Using Google Drive.\")\n",
        "    #@markdown **LOAD CHECKPOINTS FROM GOOGLE DRIVE:**\n",
        "    save_models_to_google_drive = True #@param {type:\"boolean\"}\n",
        "except:\n",
        "    is_colab = False\n",
        "    google_drive = False\n",
        "    save_models_to_google_drive = False\n",
        "    print(\"Google Colab not detected.\")\n",
        "\n",
        "if is_colab:\n",
        "    if google_drive is True:\n",
        "        drive.mount('/content/drive')\n",
        "        ai_root = '/content/drive/MyDrive/AI/KICK_GNR8R/GENERATOR'\n",
        "        root_path = f'/content'\n",
        "    else:\n",
        "        root_path = '/content'\n",
        "else:\n",
        "    root_path = os.getcwd()\n",
        "\n",
        "import os\n",
        "def createPath(filepath):\n",
        "    os.makedirs(filepath, exist_ok=True)\n",
        "\n",
        "initDirPath = f'{root_path}/init_audio'\n",
        "createPath(initDirPath)\n",
        "outDirPath = f'{root_path}/audio_out'\n",
        "createPath(outDirPath)\n",
        "\n",
        "if is_colab:\n",
        "    if google_drive and not save_models_to_google_drive or not google_drive:\n",
        "        model_path = '/content/models'\n",
        "        createPath(model_path)\n",
        "    if google_drive and save_models_to_google_drive:\n",
        "        model_path = f'{ai_root}/models'\n",
        "        createPath(model_path)\n",
        "else:\n",
        "    model_path = f'{root_path}/models'\n",
        "    createPath(model_path)\n",
        "\n",
        "# libraries = f'{root_path}/libraries'\n",
        "# createPath(libraries)\n",
        "\n",
        "#@markdown **SAVE GENERATED AUDIO TO [WEIGHTS & BIASES](https://wandb.ai/site)**\n",
        "save_to_wandb = True #@param {type: \"boolean\"}\n",
        "\n",
        "if save_to_wandb:\n",
        "    print(\"\\nInstalling wandb...\")\n",
        "    os.system(\"pip install -qqq wandb --upgrade\")\n",
        "    import wandb\n",
        "    # Check if logged in to wandb\n",
        "    try:\n",
        "      import netrc\n",
        "      netrc.netrc().hosts['api.wandb.ai']\n",
        "      wandb.login()\n",
        "    except:\n",
        "      print(\"\\nPlease log in to Weights & Biases...\")\n",
        "      print(\"1. Sign up for a free wandb account here: https://www.wandb.ai/site\")\n",
        "      print(\"2. Enter your wandb API key, from https://wandb.ai/authorize, in the field below to log in: \\n\")\n",
        "      wandb.login()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "cellView": "form",
        "id": "haxvUGZ0VpzA"
      },
      "outputs": [],
      "source": [
        "#@title DEPENDENCIES\n",
        "from prefigure.prefigure import get_all_args\n",
        "from contextlib import contextmanager\n",
        "from copy import deepcopy\n",
        "import math\n",
        "from pathlib import Path\n",
        "from google.colab import files\n",
        "\n",
        "import os, signal, sys\n",
        "import gc\n",
        "\n",
        "from diffusion import sampling\n",
        "import torch\n",
        "from torch import optim, nn\n",
        "from torch.nn import functional as F\n",
        "from torch.utils import data\n",
        "from tqdm import trange\n",
        "from einops import rearrange\n",
        "\n",
        "import torchaudio\n",
        "from audio_diffusion.models import DiffusionAttnUnet1D\n",
        "import numpy as np\n",
        "\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "import IPython.display as ipd\n",
        "from audio_diffusion.utils import Stereo, PadCrop\n",
        "from glob import glob\n",
        "\n",
        "#@title Model code\n",
        "class DiffusionUncond(nn.Module):\n",
        "    def __init__(self, global_args):\n",
        "        super().__init__()\n",
        "\n",
        "        self.diffusion = DiffusionAttnUnet1D(global_args, n_attn_layers = 4)\n",
        "        self.diffusion_ema = deepcopy(self.diffusion)\n",
        "        self.rng = torch.quasirandom.SobolEngine(1, scramble=True)\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import IPython.display as ipd\n",
        "\n",
        "def plot_and_hear(audio, sr):\n",
        "    display(ipd.Audio(audio.cpu().clamp(-1, 1), rate=sr))\n",
        "    plt.plot(audio.cpu().t().numpy())\n",
        "  \n",
        "def load_to_device(path, sr):\n",
        "    audio, file_sr = torchaudio.load(path)\n",
        "    if sr != file_sr:\n",
        "      audio = torchaudio.transforms.Resample(file_sr, sr)(audio)\n",
        "    audio = audio.to(device)\n",
        "    return audio\n",
        "\n",
        "def get_alphas_sigmas(t):\n",
        "    \"\"\"Returns the scaling factors for the clean image (alpha) and for the\n",
        "    noise (sigma), given a timestep.\"\"\"\n",
        "    return torch.cos(t * math.pi / 2), torch.sin(t * math.pi / 2)\n",
        "\n",
        "def get_crash_schedule(t):\n",
        "    sigma = torch.sin(t * math.pi / 2) ** 2\n",
        "    alpha = (1 - sigma ** 2) ** 0.5\n",
        "    return alpha_sigma_to_t(alpha, sigma)\n",
        "\n",
        "def t_to_alpha_sigma(t):\n",
        "    \"\"\"Returns the scaling factors for the clean image and for the noise, given\n",
        "    a timestep.\"\"\"\n",
        "    return torch.cos(t * math.pi / 2), torch.sin(t * math.pi / 2)\n",
        "\n",
        "def alpha_sigma_to_t(alpha, sigma):\n",
        "    \"\"\"Returns a timestep, given the scaling factors for the clean image and for\n",
        "    the noise.\"\"\"\n",
        "    return torch.atan2(sigma, alpha) / math.pi * 2\n",
        "\n",
        "#@title Args\n",
        "sample_size = 65536 \n",
        "sample_rate = 48000   \n",
        "latent_dim = 0             \n",
        "\n",
        "class Object(object):\n",
        "    pass\n",
        "\n",
        "args = Object()\n",
        "args.sample_size = sample_size\n",
        "args.sample_rate = sample_rate\n",
        "args.latent_dim = latent_dim\n",
        "\n",
        "#@title Logging\n",
        "def get_one_channel(audio_data, channel):\n",
        "  '''\n",
        "  Takes a numpy audio array and returns 1 channel\n",
        "  '''\n",
        "  # Check if the audio has more than 1 channel \n",
        "  if len(audio_data.shape) > 1:\n",
        "    is_stereo = True      \n",
        "    if np.argmax(audio_data.shape)==0:\n",
        "        audio_data = audio_data[:,channel] \n",
        "    else:\n",
        "        audio_data = audio_data[channel,:]\n",
        "  else:\n",
        "    is_stereo = False\n",
        "\n",
        "  return audio_data\n",
        "\n",
        "def log_audio_to_wandb(\n",
        "    generated, model_name, custom_ckpt_path, steps, batch_size, sample_rate, sample_size, \n",
        "    generated_all=None, channel=0, original_sample=None, gen_type='new_kicks', noise_level=None, sample_length_mult=None, file_path=None\n",
        "    ):\n",
        "\n",
        "    print('\\nSaving your audio generations to Weights & Biases...')\n",
        "\n",
        "    # Get model name\n",
        "    if model_name == \"custom\":\n",
        "      wandb_model_name = custom_ckpt_path\n",
        "    else:\n",
        "      wandb_model_name = model_name\n",
        "    \n",
        "    # Create config to log to wandb\n",
        "    wandb_config = {\n",
        "      \"model\":model_name,\n",
        "      \"steps\":steps,\n",
        "      \"batch_size\":batch_size,\n",
        "      \"sample_rate\":sample_rate,\n",
        "      \"sample_size\":sample_size,\n",
        "      \"channel\":channel,\n",
        "      \"gen_type\":gen_type,\n",
        "      \"noise_level\":noise_level,\n",
        "      \"sample_length_mult\":sample_length_mult,\n",
        "      \"file_path\":file_path\n",
        "    }\n",
        "\n",
        "    # Create a new wandb run\n",
        "    wandb.init(project='KICK-GNR8R', config=wandb_config)\n",
        "    wandb_run_url = wandb.run.get_url()\n",
        "\n",
        "    # Create a Weights & Biases Table\n",
        "    audio_generations_table = wandb.Table(columns=['audio', 'steps', 'model', 'batch_size', \n",
        "      'sample_rate', 'sample_size', 'duration'])\n",
        "\n",
        "    # Add each individual generated sample to a wandb Table\n",
        "    for idx, g in enumerate(generated.cpu().numpy()):\n",
        "    \n",
        "      # Check if the audio has more than 1 channel \n",
        "      if idx==0:  \n",
        "        if len(g.shape) > 1:\n",
        "          stereo = True      \n",
        "        else:\n",
        "          stereo = False\n",
        "\n",
        "      if stereo:\n",
        "        g = g[channel]\n",
        "\n",
        "      duration = np.max(g.shape) / sample_rate \n",
        "      wandb_audio =  wandb.Audio(g, sample_rate=sample_rate, caption=wandb_model_name)\n",
        "      audio_generations_table.add_data(wandb_audio, steps, wandb_model_name, batch_size, \n",
        "        sample_rate, sample_size, duration)\n",
        "\n",
        "    # Log the samples Tables and finish the wandb run\n",
        "    wandb.log({f'{gen_type}/kick-gnr8r' : audio_generations_table})\n",
        "    \n",
        "    # Log the combined samples in another wandb Table\n",
        "    if generated_all is not None:\n",
        "      g_all = get_one_channel(generated_all, channel)\n",
        "      duration_all = np.max(g_all.shape) / sample_rate \n",
        "      audio_all_generations_table = wandb.Table(columns=['audio', 'steps', 'model', 'batch_size', \n",
        "        'sample_rate', 'sample_size', 'duration'])\n",
        "      wandb_all_audio = wandb.Audio(g_all.cpu().numpy(), sample_rate=sample_rate, caption=wandb_model_name)\n",
        "      audio_all_generations_table.add_data(wandb_all_audio, steps, wandb_model_name, batch_size, \n",
        "        sample_rate, sample_size, duration_all)\n",
        "      wandb.log({f'{gen_type}/all_kick-gnr8r' : audio_all_generations_table})\n",
        "\n",
        "    if original_sample is not None:\n",
        "      original_sample = get_one_channel(original_sample, channel)\n",
        "      audio_original_sample_table = wandb.Table(columns=['audio', 'file_path'])\n",
        "      wandb_original_audio = wandb.Audio(original_sample, sample_rate=sample_rate)\n",
        "      audio_original_sample_table.add_data(wandb_original_audio, file_path)\n",
        "      wandb.log({f'{gen_type}/original_sample' : audio_original_sample_table})\n",
        "    \n",
        "    wandb.finish()\n",
        "\n",
        "    print(f'Your audio generations are saved in Weights & Biases here: {wandb_run_url}\\n')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SMQ8vYNQO22Y"
      },
      "source": [
        "# **MODEL SETTINGS** 🎨\n",
        "\n",
        "TUNE YOUR GENERATOR SETTINGS"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**CURRENTLY, ONLY CUSTOM MODELS ARE SUPPORTED - GENERATE CUSTOM CHECKPOINT WITH** [KICK_GNR8R_**TRNR**](https://colab.research.google.com/drive/1FkGcp0_xDHbb6Xi9BAoEDqaqwtG5twMf?usp=sharing)\n",
        "\n",
        "if you would like to contribute your datasets, please contact Digital Warfare*"
      ],
      "metadata": {
        "id": "wjZpXEAdPKUB"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LWxBqHH_Yjvt"
      },
      "source": [
        "**SELECT YOUR MODEL**\n",
        "---\n",
        "---\n",
        "---\n",
        "GENRE PACKS\n",
        "---\n",
        "Model name | Description | Sample rate | Output samples\n",
        "--- | --- | --- | ---\n",
        "RAWSTYLE |TRAINED ON XXXXXX | 48000 | 18000\n",
        "HARDSTYLE |TRAINED ON XXXXXX| 48000 | 18000\n",
        "GATED |TRAINED ON XXXXXX | 48000 | 18000\n",
        "ATONAL |TRAINED ON XXXXXX | 48000 | 18000\n",
        "REVERSE BASS |TRAINED ON XXXXXX | 48000 | 18000\n",
        "PSY |TRAINED ON XXXXXX| 48000 | 18000\n",
        "OLDSKOOL |TRAINED ON XXXXXX | 48000 | 18000\n",
        "TECHY |TRAINED ON XXXXXX| 48000 | 18000\n",
        "\n",
        "---\n",
        "---\n",
        "ARTIST PACKS\n",
        "---\n",
        "Model name | Description | Sample rate | Output samples\n",
        "--- | --- | --- | ---\n",
        "ARTIST_NAME |TRAINED ON XXXXXX | 48000 | 18000\n",
        "ARTIST_NAME |TRAINED ON XXXXXX| 48000 | 18000\n",
        "ARTIST_NAME |TRAINED ON XXXXXX | 48000 | 18000\n",
        "ARTIST_NAME |TRAINED ON XXXXXX | 48000 | 18000\n",
        "ARTIST_NAME |TRAINED ON XXXXXX | 48000 | 18000\n",
        "ARTIST_NAME |TRAINED ON XXXXXX| 48000 | 18000\n",
        "ARTIST_NAME |TRAINED ON XXXXXX | 48000 | 18000\n",
        "ARTIST_NAME |TRAINED ON XXXXXX| 48000 | 18000\n",
        "\n",
        "---\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **GENERATE MODEL** 💾\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "0FD_Y5OkPDLS"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JHsHQcc6rHu7",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "from urllib.parse import urlparse\n",
        "import hashlib\n",
        "import k_diffusion as K\n",
        "\n",
        "#@markdown ---\n",
        "\n",
        "#@markdown ###**CHOOSE YOUR MODEL**\n",
        "#@markdown CURRENTLY, ONLY CUSTOM MODELS ARE SUPPORTED - GENERATE CUSTOM CHECKPOINT WITH [KICK_GNR8R_**TRaiNR**](https://colab.research.google.com/drive/1FkGcp0_xDHbb6Xi9BAoEDqaqwtG5twMf?usp=sharing)\n",
        "model_name = \"custom\" #@param [\"RAWSTYLE\", \"HARDSTYLE\", \"GATED\", \"ATONAL\", \"REVERSE BASS\", \"PSY\", \"OLDSKOOL\", \"TECHY\", \"custom\"]\n",
        "#@markdown ---\n",
        "\n",
        "#@markdown ###**CUSTOM OPTIONS**\n",
        "#@markdown Choose the filepath for your custom model. Match parameters from training EXACTLY.\n",
        "custom_ckpt_path = '/content/drive/MyDrive/AI/KICK-GNR8R/CHECKPOINTS/HARDKICKS-V1.ckpt'#@param {type: 'string'}\n",
        "custom_sample_rate = 48000 #@param {type: 'number'}\n",
        "custom_sample_size = 65536 #@param {type: 'number'}\n",
        "\n",
        "models_map = {\n",
        "\n",
        "    \"RAWSTYLE\": {'downloaded': False,\n",
        "                         'sha': \" PLACEHOLDER \", \n",
        "                         'uri_list': [\" PLACEHOLDER \"],\n",
        "                         'sample_rate': 48000,\n",
        "                         'sample_size': 65536\n",
        "                         },\n",
        "    \"HARDSTYLE\": {'downloaded': False,\n",
        "                         'sha': \" PLACEHOLDER \", \n",
        "                         'uri_list': [\" PLACEHOLDER \"],\n",
        "                         'sample_rate': 48000,\n",
        "                         'sample_size': 65536\n",
        "                         },\n",
        "    \"GATED\": {'downloaded': False,\n",
        "                         'sha': \" PLACEHOLDER \", \n",
        "                         'uri_list': [\" PLACEHOLDER \"],\n",
        "                         'sample_rate': 48000,\n",
        "                         'sample_size': 131072\n",
        "                         },\n",
        "    \"ATONAL\": {'downloaded': False,\n",
        "                         'sha': \" PLACEHOLDER \", \n",
        "                         'uri_list': [\" PLACEHOLDER \"],\n",
        "                         'sample_rate': 48000,\n",
        "                         'sample_size': 65536\n",
        "                         },\n",
        "    \"REVERSE BASS\": {'downloaded': False,\n",
        "                         'sha': \" PLACEHOLDER \", \n",
        "                         'uri_list': [\" PLACEHOLDER \"],\n",
        "                         'sample_rate': 48000,\n",
        "                         'sample_size': 65536\n",
        "                         },\n",
        "    \"PSY\": {'downloaded': False,\n",
        "                         'sha': \" PLACEHOLDER \", \n",
        "                         'uri_list': [\" PLACEHOLDER \"],\n",
        "                         'sample_rate': 48000,\n",
        "                         'sample_size': 65536\n",
        "                         },\n",
        "    \"OLDSKOOL\": {'downloaded': False,\n",
        "                         'sha': \" PLACEHOLDER \", \n",
        "                         'uri_list': [\" PLACEHOLDER \"],\n",
        "                         'sample_rate': 48000,\n",
        "                         'sample_size': 65536\n",
        "                         },\n",
        "    \"TECHY\": {'downloaded': False,\n",
        "                         'sha': \" PLACEHOLDER \", \n",
        "                         'uri_list': [\" PLACEHOLDER \"],\n",
        "                         'sample_rate': 48000,\n",
        "                         'sample_size': 65536\n",
        "                         },\n",
        "}\n",
        "#@markdown ---\n",
        "## #@markdown If you're having issues with model downloads, check this to compare the SHA:\n",
        "## check_model_SHA = False #@param{type:\"boolean\"}\n",
        "\n",
        "def get_model_filename(diffusion_model_name):\n",
        "    model_uri = models_map[diffusion_model_name]['uri_list'][0]\n",
        "    model_filename = os.path.basename(urlparse(model_uri).path)\n",
        "    return model_filename\n",
        "\n",
        "def download_model(diffusion_model_name, uri_index=0):\n",
        "    if diffusion_model_name != 'custom':\n",
        "        model_filename = get_model_filename(diffusion_model_name)\n",
        "        model_local_path = os.path.join(model_path, model_filename)\n",
        "        if os.path.exists(model_local_path) and check_model_SHA:\n",
        "            print(f'Checking {diffusion_model_name} File')\n",
        "            with open(model_local_path, \"rb\") as f:\n",
        "                bytes = f.read() \n",
        "                hash = hashlib.sha256(bytes).hexdigest()\n",
        "                print(f'SHA: {hash}')\n",
        "            if hash == models_map[diffusion_model_name]['sha']:\n",
        "                print(f'{diffusion_model_name} SHA matches')\n",
        "                models_map[diffusion_model_name]['downloaded'] = True\n",
        "            else:\n",
        "                print(f\"{diffusion_model_name} SHA doesn't match. Will redownload it.\")\n",
        "        elif os.path.exists(model_local_path) and not check_model_SHA or models_map[diffusion_model_name]['downloaded']:\n",
        "            print(f'{diffusion_model_name} already downloaded. If the file is corrupt, enable check_model_SHA.')\n",
        "            models_map[diffusion_model_name]['downloaded'] = True\n",
        "\n",
        "        if not models_map[diffusion_model_name]['downloaded']:\n",
        "            for model_uri in models_map[diffusion_model_name]['uri_list']:\n",
        "                wget(model_uri, model_local_path)\n",
        "                with open(model_local_path, \"rb\") as f:\n",
        "                  bytes = f.read() \n",
        "                  hash = hashlib.sha256(bytes).hexdigest()\n",
        "                  print(f'SHA: {hash}')\n",
        "                if os.path.exists(model_local_path):\n",
        "                    models_map[diffusion_model_name]['downloaded'] = True\n",
        "                    return\n",
        "                else:\n",
        "                    print(f'{diffusion_model_name} model download from {model_uri} failed. Will try any fallback uri.')\n",
        "            print(f'{diffusion_model_name} download failed.')\n",
        "\n",
        "if model_name == \"custom\":\n",
        "  ckpt_path = custom_ckpt_path\n",
        "  args.sample_size = custom_sample_size\n",
        "  args.sample_rate = custom_sample_rate\n",
        "else:\n",
        "  model_info = models_map[model_name]\n",
        "  download_model(model_name)\n",
        "  ckpt_path = f'{model_path}/{get_model_filename(model_name)}'\n",
        "  args.sample_size = model_info[\"sample_size\"]\n",
        "  args.sample_rate = model_info[\"sample_rate\"]\n",
        "\n",
        "print(\"Creating the model...\")\n",
        "model = DiffusionUncond(args)\n",
        "model.load_state_dict(torch.load(ckpt_path)[\"state_dict\"])\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = model.requires_grad_(False).to(device)\n",
        "print(\"Model created\")\n",
        "\n",
        "# # Remove non-EMA\n",
        "del model.diffusion\n",
        "\n",
        "model_fn = model.diffusion_ema"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **SAMPLER SETTINGS** 🧮"
      ],
      "metadata": {
        "id": "YzqptQBcS-AI"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Knzr6CYmtaI_"
      },
      "source": [
        "Noise Samplers introduce a specific type of randomness into the diffusion process. Each sampler has a different 'flavor' of output and can be used to guide the character of the generated file.\n",
        "\n",
        "---\n",
        "\n",
        "**NOISE SAMPLER TYPES**\n",
        "\n",
        "---\n",
        "Sampler name | Notes | Defaults\n",
        "--- | --- | ---\n",
        "v-iplms | **DEFAULT SAMPLER** - *For Generating Random Full Kicks* | 0.0001 , 1, 7, 0.1, 0.1\n",
        "k-heun | Needs fewer steps, but ideal sigma_min and sigma_max need to be found. Doesn't work with all models. | DEFINE\n",
        "k-dpmpp_2s_ancestral | Fastest sampler, but you may have to find new sigmas. Recommended min & max sigmas: 0.01, 80 | DEFINE\n",
        "k-lms | **Caution** Very noisy, use for highend | DEFINE\n",
        "k-dpm-2 | Good for character, noise, and crunches | DEFINE\n",
        "k-dpm-fast | Good for Attacks, Toks and Punches | DEFINE\n",
        "k-dpm-adaptive | Takes in extra parameters for quality, step count is non-deterministic | DEFINE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iyR4w86-ei_z",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@markdown **SAMPLER OPTIONS**\n",
        "#@markdown ---\n",
        "#@markdown **SAMPLER TYPE**\n",
        "sampler_type = \"v-iplms\" #@param [\"v-iplms\", \"k-heun\", \"k-dpmpp_2s_ancestral\", \"k-lms\", \"k-dpm-2\", \"k-dpm-fast\", \"k-dpm-adaptive\"]\n",
        "\n",
        "#@markdown ---\n",
        "#@markdown **K-DIFFUSION SETTINGS (advanced)**\n",
        "#@markdown *Input Noise distribution values*\n",
        "#@markdown\n",
        "#@markdown Sigma = Noise Amplitude  |  Rho = Noise Frequency\n",
        "sigma_min = 0.001 #@param {type: \"number\"}\n",
        "sigma_max = 1 #@param {type: \"number\"}\n",
        "rho=7. #@param {type: \"number\"}\n",
        "#@markdown ---\n",
        "#@markdown **K-DPM-ADAPTIVE SETTINGS**\n",
        "#@markdown\n",
        "#@markdown Relative/Absolute Tolerance deetrmine the tolerance of error when recognizing patterns in noise (smaller values = more accurate results)\n",
        "rtol = 0.01 #@param {type: \"number\"}\n",
        "atol = 0.01 #@param {type: \"number\"}\n",
        "\n",
        "def sample(model_fn, noise, steps=100, sampler_type=\"v-iplms\", noise_level = 1.0):\n",
        "  #Check for k-diffusion\n",
        "  if sampler_type.startswith('k-'):\n",
        "    denoiser = K.external.VDenoiser(model_fn)\n",
        "    sigmas = K.sampling.get_sigmas_karras(steps, sigma_min, sigma_max, rho, device=device)\n",
        "\n",
        "  if sampler_type == \"v-iplms\":\n",
        "    t = torch.linspace(1, 0, steps + 1, device=device)[:-1]\n",
        "    step_list = get_crash_schedule(t)\n",
        "\n",
        "    return sampling.iplms_sample(model_fn, noise, step_list, {})\n",
        "\n",
        "  elif sampler_type == \"k-heun\":\n",
        "    return K.sampling.sample_heun(denoiser, noise, sigmas, disable=False)\n",
        "  elif sampler_type == \"k-lms\":\n",
        "    return K.sampling.sample_lms(denoiser, noise, sigmas, disable=False)\n",
        "  elif sampler_type == \"k-dpmpp_2s_ancestral\":\n",
        "    return K.sampling.sample_dpmpp_2s_ancestral(denoiser, noise, sigmas, disable=False)\n",
        "  elif sampler_type == \"k-dpm-2\":\n",
        "    return K.sampling.sample_dpm_2(denoiser, noise, sigmas, disable=False)\n",
        "  elif sampler_type == \"k-dpm-fast\":\n",
        "    return K.sampling.sample_dpm_fast(denoiser, noise, sigma_min, sigma_max, steps, disable=False)\n",
        "  elif sampler_type == \"k-dpm-adaptive\":\n",
        "    return K.sampling.sample_dpm_adaptive(denoiser, noise, sigma_min, sigma_max, rtol=rtol, atol=atol, disable=False)\n",
        "\n",
        "def resample(model_fn, audio, steps=100, sampler_type=\"v-iplms\", noise_level = 1.0):\n",
        "  #Noise the input\n",
        "  if sampler_type == \"v-iplms\":\n",
        "    t = torch.linspace(0, 1, steps + 1, device=device)\n",
        "    step_list = get_crash_schedule(t)\n",
        "    step_list = step_list[step_list < noise_level]\n",
        "\n",
        "    alpha, sigma = t_to_alpha_sigma(step_list[-1])\n",
        "    noised = torch.randn([batch_size, 2, effective_length], device='cuda')\n",
        "    noised = audio * alpha + noised * sigma\n",
        "\n",
        "  elif sampler_type.startswith(\"k-\"):\n",
        "    denoiser = K.external.VDenoiser(model_fn)\n",
        "    noised = audio + torch.randn_like(audio) * noise_level\n",
        "    sigmas = K.sampling.get_sigmas_karras(steps, sigma_min, noise_level, rho, device=device)\n",
        "\n",
        "  # Denoise\n",
        "  if sampler_type == \"v-iplms\":\n",
        "    return sampling.iplms_sample(model_fn, noised, step_list.flip(0)[:-1], {})\n",
        "\n",
        "  elif sampler_type == \"k-heun\":\n",
        "    return K.sampling.sample_heun(denoiser, noised, sigmas, disable=False)\n",
        "\n",
        "  elif sampler_type == \"k-dpmpp_2s_ancestral\":\n",
        "    return K.sampling.sample_dpmpp_2s_ancestral(denoiser, noised, sigmas, disable=False)\n",
        "\n",
        "  elif sampler_type == \"k-lms\":\n",
        "    return K.sampling.sample_lms(denoiser, noised, sigmas, disable=False)\n",
        "\n",
        "  elif sampler_type == \"k-dpm-2\":\n",
        "    return K.sampling.sample_dpm_2(denoiser, noised, sigmas, s_noise=0., disable=False)\n",
        "\n",
        "  elif sampler_type == \"k-dpm-fast\":\n",
        "    return K.sampling.sample_dpm_fast(denoiser, noised, sigma_min, noise_level, steps, disable=False)\n",
        "\n",
        "  elif sampler_type == \"k-dpm-adaptive\":\n",
        "    return K.sampling.sample_dpm_adaptive(denoiser, noised, sigma_min, noise_level, rtol=rtol, atol=atol, disable=False)\n",
        "\n",
        "def reverse_sample(model_fn, audio, steps=100, sampler_type=\"v-iplms\", noise_level = 1.0):\n",
        "  \n",
        "  if sampler_type == \"v-iplms\":\n",
        "    t = torch.linspace(0, 1, steps + 1, device=device)\n",
        "    step_list = get_crash_schedule(t)\n",
        "\n",
        "    return sampling.iplms_sample(model_fn, audio_samples, step_list, {}, is_reverse=True)\n",
        "\n",
        "  elif sampler_type.startswith(\"k-\"):\n",
        "    denoiser = K.external.VDenoiser(model_fn)\n",
        "    sigmas = K.sampling.get_sigmas_karras(steps, sigma_min, noise_level, rho, device=device)\n",
        "\n",
        "  # Denoise\n",
        "  if sampler_type == \"k-heun\":\n",
        "    return K.sampling.sample_heun(denoiser, audio, sigmas.flip(0)[:-1], disable=False)\n",
        "  elif sampler_type == \"k-lms\":\n",
        "    return K.sampling.sample_lms(denoiser, audio, sigmas.flip(0)[:-1], disable=False)\n",
        "  elif sampler_type == \"k-dpmpp_2s_ancestral\":\n",
        "    return K.sampling.sample_dpmpp_2s_ancestral(denoiser, audio, sigmas.flip(0)[:-1], disable=False)\n",
        "  elif sampler_type == \"k-dpm-2\":\n",
        "    return K.sampling.sample_dpm_2(denoiser, audio, sigmas.flip(0)[:-1], s_noise=0., disable=False)\n",
        "  elif sampler_type == \"k-dpm-fast\":\n",
        "    return K.sampling.sample_dpm_fast(denoiser, audio, noise_level, sigma_min, steps, disable=False)\n",
        "\n",
        "  elif sampler_type == \"k-dpm-adaptive\":\n",
        "    return K.sampling.sample_dpm_adaptive(denoiser, audio, noise_level, sigma_min, rtol=rtol, atol=atol, disable=False)\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_GQK9yZHTr_z"
      },
      "source": [
        "# **- KICK-GNR8R -** 🧪\n",
        "\n",
        "GENERATE KICK SAMPLES"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zntGqLTJq6xU",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@markdown ###**GENERATE AUDIO**\n",
        "#@markdown ---\n",
        "#@markdown **NUMBER OF KICKS TO GENERATE**\n",
        "batch_size =  1#@param {type:\"number\"}\n",
        "#@markdown ---\n",
        "#@markdown **NUMBER OF STEPS** *(100-400 noisy 500+ Good*)\n",
        "steps = 1500 #@param {type:\"number\"}\n",
        "#@markdown ---\n",
        "#@markdown **SAMPLE LENGTH MULTIPLIER**  *(1=18000smp)* \n",
        "\n",
        "sample_length_mult = 1#@param {type:\"number\"}\n",
        "\n",
        "#@markdown ---\n",
        "\n",
        "#@markdown Check the box below to save your generated audio to [Weights & Biases](https://www.wandb.ai/site)\n",
        "save_new_generations_to_wandb = True #@param {type: \"boolean\"}\n",
        "\n",
        "## #@markdown Check the box below to skip this section when running all cells\n",
        "## skip_for_run_all = False #@param {type: \"boolean\"}\n",
        "\n",
        "#@markdown ---\n",
        "\n",
        "effective_length = sample_length_mult * args.sample_size\n",
        "\n",
        "if not skip_for_run_all:\n",
        "  torch.cuda.empty_cache()\n",
        "  gc.collect()\n",
        "\n",
        "  # Generate random noise to sample from\n",
        "  noise = torch.randn([batch_size, 2, effective_length]).to(device)\n",
        "\n",
        "  generated = sample(model_fn, noise, steps, sampler_type)\n",
        "\n",
        "  # Hard-clip the generated audio\n",
        "  generated = generated.clamp(-1, 1)\n",
        "\n",
        "  # Put the demos together\n",
        "  generated_all = rearrange(generated, 'b d n -> d (b n)')\n",
        "\n",
        "  print(\"All samples\")\n",
        "  plot_and_hear(generated_all, args.sample_rate)\n",
        "  for ix, gen_sample in enumerate(generated):\n",
        "    print(f'sample #{ix + 1}')\n",
        "    display(ipd.Audio(gen_sample.cpu(), rate=args.sample_rate))\n",
        "\n",
        "  # If Weights & Biases logging enabled, save generations\n",
        "  if save_new_generations_to_wandb:\n",
        "    # Check if logged in to wandb\n",
        "    try:\n",
        "      import netrc\n",
        "      netrc.netrc().hosts['api.wandb.ai']\n",
        "\n",
        "      log_audio_to_wandb(generated, model_name, custom_ckpt_path, steps, batch_size, \n",
        "      args.sample_rate, args.sample_size, generated_all=generated_all)\n",
        "    except:\n",
        "      print(\"Not logged in to Weights & Biases, please tick the `save_to_wandb` box at the top of this notebook and run that cell again to log in to Weights & Biases first\")\n",
        "\n",
        "else:\n",
        "  print(\"Skipping section, uncheck 'skip_for_run_all' to enable\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **- SAMPLE R3GENR8R -**  💱\n",
        "\n",
        "EXTRA TOOLS AND MODULES"
      ],
      "metadata": {
        "id": "tVmF1juzHbmC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **INFO** 📕\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "yMrSeAuGHlmZ"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v0WKP7ku67vn"
      },
      "source": [
        "***ALPHA FEATURES - MAY BE BUGGY***\n",
        "\n",
        "Regenerate your own samples to achieve unique results.\n",
        "By routing an audio sample into the noise sampler, you can transfer the sonic qualities of the neural net to this sound. There are 3 styles in this model:\n",
        "\n",
        "- ### **LAYER & MIX**\n",
        "> Equivalent of layering and mixing in sound design, this feature can mix sounds together using the neural net to produce surprisingly unique results. Use this module to layer Kicks together, or for example to mix screeches and kicks together.\n",
        "> - To layer differnet sounds, export stems (i.e. 16 beat screech pattern and 16beat kick pattern)\n",
        ">> ***(currently only supports mic input recording, but you can route DAW to mic input to record samples)***\n",
        ">>> -  [ A + B = C ]\n",
        "\n",
        "- ### **STYLE TRANSFER**\n",
        "> Transfers the sonic qualities of the model to another sound. Makes everything sound like a hardstyle kick. Speech segments and Vocal phonetics like vowels, especially if pitched to kick frequencies sound the best. Great for making crunchy vocals or gnarly atmospheres.\n",
        ">> - ***(currently only supports mic input recording, but you can route DAW to mic input to record samples)***\n",
        ">>> -  [ A / B = C ]\n",
        "\n",
        "- ### **INTERPOLATE**\n",
        "> This module takes two sounds and generates intermediate steps between the two. This is great for blending one kick into another over the course of a specified quantity, or creating awesome transitions and blends.\n",
        "> - Add Source and Target fies, specify number of interpolation steps in odd numbers, specify the number of generation steps.\n",
        "> -To get blended builds, take the result files and stack ontop of eachother, blending from one clip to another.\n",
        ">> - [ (A/x) * B = C ]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **MODULES** 🔌\n"
      ],
      "metadata": {
        "id": "itWWTFtlI5XM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **LAYER & MIX** 🍔 🧫\n",
        "\n"
      ],
      "metadata": {
        "id": "shMDngHbJAAC"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oTK_JxQ0arky",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchaudio\n",
        "from typing import Iterable, Tuple\n",
        "import gradio as gr\n",
        "\n",
        "Audio = Tuple[int, np.ndarray]\n",
        "\n",
        "\n",
        "#@markdown LAYER AND MIX MULTIPLE FILES\n",
        "#@markdown ---\n",
        "#@markdown ---\n",
        "#@markdown **CHECK TO CREATE RECORDING INTERFACE**\n",
        "record_audio = True #@param {type: \"boolean\"}\n",
        "\n",
        "#@markdown ---\n",
        "#@markdown **TARGET FILE PATH**\n",
        "\n",
        "#@markdown *(Insert filepath or leave blank to upload file from interface)*\n",
        "file_path = \"\" #@param{type:\"string\"}\n",
        "\n",
        "#@markdown ---\n",
        "#@markdown **NUMBER OF RECORDINGS/FILES**\n",
        "\n",
        "#@markdown *(Only applies if the \"record_audio\" box is checked)*\n",
        "n_audio_recordings = 2 #@param{type:\"number\"}\n",
        "\n",
        "# this is a global variable to be filled in by the generate_from_audio callback\n",
        "recording_file_path = \"\"\n",
        "#@markdown ---\n",
        "\n",
        "def combine_audio(*audio_iterable: Iterable[Audio]) -> Audio:\n",
        "    \"\"\"Combines an iterable of audio signals into one.\"\"\"\n",
        "    max_len = max([x.shape for _, x in audio_iterable])\n",
        "    combined_audio = np.zeros(max_len, dtype=np.int32)\n",
        "    for _, a in audio_iterable:\n",
        "        combined_audio[:a.shape[0]] = combined_audio[:a.shape[0]] * .5 + a * .5\n",
        "    return combined_audio\n",
        "\n",
        "\n",
        "def generate_from_audio(file_path: str, *audio_iterable: Iterable[Audio]):\n",
        "    sample_rate = audio_iterable[0][0]\n",
        "    combined_audio = combine_audio(*audio_iterable)\n",
        "    tensor = torch.from_numpy(\n",
        "        np.concatenate(\n",
        "            [\n",
        "                combined_audio.reshape(1, -1),\n",
        "                combined_audio.reshape(1, -1)\n",
        "            ],\n",
        "            axis=0,\n",
        "        )\n",
        "    )\n",
        "    global recording_file_path\n",
        "    recording_file_path = file_path\n",
        "    torchaudio.save(\n",
        "        file_path,\n",
        "        tensor,\n",
        "        sample_rate=sample_rate,\n",
        "        format=\"wav\"\n",
        "    )\n",
        "    return (sample_rate, combined_audio), file_path\n",
        "\n",
        "if record_audio:\n",
        "    recording_interface = gr.Interface(\n",
        "        fn=generate_from_audio,\n",
        "        inputs=[\n",
        "            gr.Textbox(\n",
        "                \"/content/recording.wav\",\n",
        "                label=\"save recording to filepath\",\n",
        "            ),\n",
        "            *[\n",
        "                gr.Audio(source=\"microphone\", label=f\"audio clip {i}\")\n",
        "                for i in range(1, n_audio_recordings + 1)\n",
        "            ]\n",
        "        ],\n",
        "        outputs=[\n",
        "            gr.Audio(label=\"combined output audio\"),\n",
        "            gr.File(label=\"output file\"),\n",
        "        ],\n",
        "        allow_flagging=\"never\",\n",
        "    )\n",
        "\n",
        "    recording_interface.launch(debug=True);\n",
        "elif file_path == \"\":\n",
        "    print(\"No file path provided, please upload a file\")\n",
        "    # uploaded = files.upload()\n",
        "    file_path = list(uploaded.keys())[0]\n",
        "\n",
        "if not record_audio:\n",
        "    print(f\"Using file_path: {file_path} to regenerate new sounds.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **STYLE TRANSFER** 🤼"
      ],
      "metadata": {
        "id": "3v8jprpnJGye"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "bKgS7vZc4lN9"
      },
      "outputs": [],
      "source": [
        "#@markdown **STYLE TRANSFER PARAMETERS**\n",
        "#@markdown ---\n",
        "#@markdown *(only works on recorded audio from LAYER & MIX)*\n",
        "#@markdown ---\n",
        "#@markdown ---\n",
        "\n",
        "\n",
        "#@markdown **GENERATION STEPS** *(100-300=Low +700=High)*\n",
        "steps = 700 #@param {type:\"slider\", min:10, max:2000, step:10}\n",
        "#@markdown ---\n",
        "\n",
        "#@markdown **SOURCE : NOISE RATIO** ***(dry/wet)***\n",
        "#@markdown \n",
        "noise_level = 0.7 #@param {type:\"slider\", min:0, max:1, step:0.01}\n",
        "#@markdown ---\n",
        "\n",
        "#@markdown **SAMPLE LENGTH MULTIPLIER**\n",
        "sample_length_mult = 1#@param {type:\"number\"}\n",
        "#@markdown ---\n",
        "\n",
        "#@markdown **VARIATIONS**\n",
        "batch_size = 4 #@param {type:\"number\"}\n",
        "#@markdown ---\n",
        "\n",
        "#@markdown **[CHECK]** **TO SAVE TO [WEIGHTS & BIASES](https://www.wandb.ai/site)**\n",
        "save_own_generations_to_wandb = True #@param {type: \"boolean\"}\n",
        "#@markdown ---\n",
        "\n",
        "## #@markdown **[CHECK]** **TO SKIP RUN_ALL**\n",
        "## skip_for_run_all = False #@param {type: \"boolean\"}\n",
        "\n",
        "\n",
        "effective_length = args.sample_size * sample_length_mult\n",
        "\n",
        "if not skip_for_run_all:\n",
        "  torch.cuda.empty_cache()\n",
        "  gc.collect()\n",
        "\n",
        "  augs = torch.nn.Sequential(\n",
        "    PadCrop(effective_length, randomize=True),\n",
        "    Stereo()\n",
        "  )\n",
        "\n",
        "  fp = recording_file_path if record_audio else file_path\n",
        "\n",
        "  audio_sample = load_to_device(fp, args.sample_rate)\n",
        "\n",
        "  audio_sample = augs(audio_sample).unsqueeze(0).repeat([batch_size, 1, 1])\n",
        "\n",
        "  print(\"Initial audio sample\")\n",
        "  plot_and_hear(audio_sample[0], args.sample_rate)\n",
        "  \n",
        "  generated = resample(model_fn, audio_sample, steps, sampler_type, noise_level=noise_level)\n",
        "\n",
        "  print(\"Regenerated audio samples\")\n",
        "  plot_and_hear(rearrange(generated, 'b d n -> d (b n)'), args.sample_rate)\n",
        "\n",
        "  for ix, gen_sample in enumerate(generated):\n",
        "    print(f'sample #{ix + 1}')\n",
        "    display(ipd.Audio(gen_sample.cpu(), rate=args.sample_rate))\n",
        "\n",
        "  # If Weights & Biases logging enabled, save generations\n",
        "  if save_own_generations_to_wandb:\n",
        "    # Check if logged in to wandb\n",
        "    try:\n",
        "      import netrc\n",
        "      netrc.netrc().hosts['api.wandb.ai']\n",
        "\n",
        "      log_audio_to_wandb(generated, model_name, custom_ckpt_path, steps, batch_size, \n",
        "        args.sample_rate, args.sample_size, file_path=fp, original_sample=audio_sample[0].cpu().numpy(),\n",
        "        noise_level=noise_level, gen_type='own_file')\n",
        "    except:\n",
        "      print(\"Not logged in to Weights & Biases, please tick the `save_to_wandb` box at the top of this notebook and run that cell again to log in to Weights & Biases first\")\n",
        "\n",
        "else:\n",
        "  print(\"Skipping section, uncheck 'skip_for_run_all' to enable\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **INTERPOL8R** 📈"
      ],
      "metadata": {
        "id": "xN5vY9G7JMBu"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "l3Al3thgO5rb"
      },
      "outputs": [],
      "source": [
        "#@markdown **INTERPOLATOR**\n",
        "#@markdown ---\n",
        "#@markdown ---\n",
        "\n",
        "#@markdown **BEST RESULTS:**\n",
        "#@markdown - Audio FIles must be in the same key (run standardize.py or pitchshift.py to process all files to the same key )\n",
        "#@markdown - Odd Number of Interpolations\n",
        "#@markdown - Longer samples create more noticeable results\n",
        "\n",
        "#@markdown ---\n",
        "\n",
        "# Interpolation code taken and modified from CRASH\n",
        "def compute_interpolation_in_latent(latent1, latent2, lambd):\n",
        "    '''\n",
        "    Implementation of Spherical Linear Interpolation: https://en.wikipedia.org/wiki/Slerp\n",
        "    latent1: tensor of shape (2, n)\n",
        "    latent2: tensor of shape (2, n)\n",
        "    lambd: list of floats between 0 and 1 representing the parameter t of the Slerp\n",
        "    '''\n",
        "    device = latent1.device\n",
        "    lambd = torch.tensor(lambd)\n",
        "\n",
        "    assert(latent1.shape[0] == latent2.shape[0])\n",
        "\n",
        "    # get the number of channels\n",
        "    nc = latent1.shape[0]\n",
        "    interps = []\n",
        "    for channel in range(nc):\n",
        "    \n",
        "      cos_omega = latent1[channel]@latent2[channel] / \\\n",
        "          (torch.linalg.norm(latent1[channel])*torch.linalg.norm(latent2[channel]))\n",
        "      omega = torch.arccos(cos_omega).item()\n",
        "\n",
        "      a = torch.sin((1-lambd)*omega) / np.sin(omega)\n",
        "      b = torch.sin(lambd*omega) / np.sin(omega)\n",
        "      a = a.unsqueeze(1).to(device)\n",
        "      b = b.unsqueeze(1).to(device)\n",
        "      interps.append(a * latent1[channel] + b * latent2[channel])\n",
        "    return rearrange(torch.cat(interps), \"(c b) n -> b c n\", c=nc) \n",
        "\n",
        "#@markdown **AUDIO FILES TO INTERPOLATE**\n",
        "source_audio_path = \"\" #@param{type:\"string\"}\n",
        "target_audio_path = \"\" #@param{type:\"string\"}\n",
        "#@markdown ---\n",
        "#@markdown **GENERATION STEPS** *(100-300=Low +700=High)*\n",
        "steps = 600#@param {type:\"number\"}\n",
        "#@markdown ---\n",
        "#@markdown **INTERPOLATED SAMPLES** (Odd Number)\n",
        "n_interps = 3 #@param {type:\"slider\", min:3, max:100, step:2}\n",
        "#@markdown ---\n",
        "#@markdown **SAMPLE LENGTH MULTIPLIER**\n",
        "sample_length_mult = 1#@param {type:\"number\"}\n",
        "#@markdown ---\n",
        "#@markdown **SKIP RUN ALL CELLS**\n",
        "skip_for_run_all = False #@param {type: \"boolean\"}\n",
        "\n",
        "#@markdown ---\n",
        "\n",
        "effective_length = args.sample_size * sample_length_mult\n",
        "\n",
        "if not skip_for_run_all:\n",
        "\n",
        "  augs = torch.nn.Sequential(\n",
        "    PadCrop(effective_length, randomize=True),\n",
        "    Stereo()\n",
        "  )\n",
        "\n",
        "  if source_audio_path == \"\":\n",
        "    print(\"No file path provided for the source audio, please upload a file\")\n",
        "    uploaded = files.upload()\n",
        "    source_audio_path = list(uploaded.keys())[0]\n",
        "\n",
        "  audio_sample_1 = load_to_device(source_audio_path, args.sample_rate)\n",
        "\n",
        "  print(\"Source audio sample loaded\")\n",
        "\n",
        "  if target_audio_path == \"\":\n",
        "    print(\"No file path provided for the target audio, please upload a file\")\n",
        "    uploaded = files.upload()\n",
        "    target_audio_path = list(uploaded.keys())[0]\n",
        "\n",
        "  audio_sample_2 = load_to_device(target_audio_path, args.sample_rate)\n",
        "\n",
        "  print(\"Target audio sample loaded\")\n",
        "\n",
        "  audio_samples = augs(audio_sample_1).unsqueeze(0).repeat([2, 1, 1])\n",
        "  audio_samples[1] = augs(audio_sample_2)\n",
        "\n",
        "  print(\"Initial audio samples\")\n",
        "  plot_and_hear(audio_samples[0], args.sample_rate)\n",
        "  plot_and_hear(audio_samples[1], args.sample_rate)\n",
        "\n",
        "  reversed = reverse_sample(model_fn, audio_samples, steps)\n",
        "\n",
        "  latent_series = compute_interpolation_in_latent(reversed[0], reversed[1], [k/n_interps for k in range(n_interps + 2)])\n",
        "\n",
        "  generated = sample(model_fn, latent_series, steps) \n",
        "  \n",
        "  #sampling.iplms_sample(, latent_series, step_list.flip(0)[:-1], {})\n",
        "\n",
        "  # Put the demos together\n",
        "  generated_all = rearrange(generated, 'b d n -> d (b n)')\n",
        "\n",
        "  print(\"Full interpolation\")\n",
        "  plot_and_hear(generated_all, args.sample_rate)\n",
        "  for ix, gen_sample in enumerate(generated):\n",
        "    print(f'sample #{ix + 1}')\n",
        "    display(ipd.Audio(gen_sample.cpu(), rate=args.sample_rate))\n",
        "else:\n",
        "  print(\"Skipping section, uncheck 'skip_for_run_all' to enable\") "
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "4bZV23WUnC3U",
        "1iZwJ9ong-pH",
        "pJkAc1j4pfAt",
        "lU97ZiP7nSKS",
        "iJhSysRdwku9",
        "SMQ8vYNQO22Y",
        "YzqptQBcS-AI",
        "_GQK9yZHTr_z",
        "tVmF1juzHbmC",
        "yMrSeAuGHlmZ",
        "itWWTFtlI5XM",
        "shMDngHbJAAC",
        "3v8jprpnJGye",
        "xN5vY9G7JMBu"
      ]
    },
    "gpuClass": "premium",
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}